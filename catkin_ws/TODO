
Testing:
	✔ Test the system driving in a straight line instead of spinning @30m @started(20-03-25 13:41) @done(20-03-25 14:14) @lasted(33m17s)
		Localises better when going in a straight line, but the matching is still a bit dodgy...
		There's a bug with the motor code it seems - the jitters when going straight are coming from commanded motor speeds
	✔ Do a couple of runs and make a confusion matrix to test the raw matching (maybe need normxcorr?) @45m @started(20-03-26 8:14) @done(20-03-26 09:02) @lasted(48m34s)
		Matching looks OK, but the offsets all come out as ~ -60. Should investigate this. Bug fixed!
	✔ Testing while actually driving straight thanks to the new controller @15m @started(20-03-26 10:45) @done(20-03-26 10:58) @lasted(13m25s)
		Again, matching looks OK (not perfect - sometimes it matches crazy images at big offsets...) Controller isn't great though - bad odom drift
	✔ Collect some more datasets to test the image recognition against @done(20-03-26 16:06)
		The wheel locking up seems to exclusively happen on the carpet, and _potentially_ happen more at lower speeds (wheel locking due to low torque?)
		It's weird that the commanded right motor speed is set to zero though -> is this actually something else, like odom?
		Odom on the lino floor also looks a lot better than odom on the carpet
	✔ Test visual odometry for rotation @30m @started(20-03-31 9:50) @done(20-03-31 10:37) @lasted(47m38s)
		Works ok but will need some tuning
		Issues - 
			* want to narrow the field of view so there's less movement at the sides when going straight
			* but narrowing the field of view limits the max tracked turning speed
			* so... need to capture at a higher frame rate for VO
			* want to do better stereo unwarping so the centre of the image looks less crazy
	✔ Develop basic tests for the teach-repeat (straight line, L, loop) @done(20-04-28 10:44)
		Outdoor path, indoor path, outdoor loop, straight line
	✔ Test current approach to get a benchmark @done(20-04-28 10:46)
		Works quite well on all paths - initial offsets cause failure though
	✔ Investigate whether not accounting for known goal->odom theta offset is causing issues @started(20-04-30 16:34) @done(20-04-30 17:16) @lasted(42m28s)
		* In sim, it needs some work to surface, but can be seen to cause issues
	✔ Test along-route localisation @done(20-05-11 14:10)
		* Works nicely for a ~30 m outdoor->indoor route using +/- 50% correction (+/-10% artificial linear odom error)
	✔ Testing the breaking point of along-route localisation (what % odom corruption) @done(20-05-14 14:06)
	✔ Test effect of moving the robot +/- 1 metre along the path -> along path localisation @done(20-05-20 15:52)
	☐ Test robot in more complex environments (turning on spot, there and back)
	☐ What happens when running path correction but no orientation correction?

	Issues and Ideas:
		☐ Background tends to dominate correlation offset -> driving from open to enclosed space unreliable
			* eg. under-table2_tests/3/733
			* Have a weighting kernel applied over the reference image: centre is most important (direction of travel)
		☐ Centre correction on last goal or on robot - which is better?
			* last goal: has issues with big corrections at high u (new goal becomes unreachable)
			* robot: seems to make corrections converge more slowly? Maybe up gain?
				* this seems to be working well
		☐ Should there be path or orientation corrections during turns?
			* path correction: have no effect, so it's pointless
			* orientation correction should work ok -> need to test
				* It's actually more like along-path correction...	
		☐ Definite issue if Miro stops rotating - big errors accumulate
		☐ Big theta correction errors at the start/end of turns

Development:
	Setup:
		✔ Stitch the camera images together @done(20-03-25 10:52)
			✔ Sync the camera images by approximately stamping them @started(20-03-25 09:34) @done(20-03-25 10:27) @lasted(53m10s)
			✔ Use 50% blending for the image stitching @done(20-03-25 10:28)
			✔ Use linear blending @started(20-03-25 10:45) @done(20-03-25 10:52) @lasted(7m16s)
		✔ Calibrate the cameras to be properly aligned @done(20-07-13 09:00)
	
	Localisation / Image Processing:
		✔ Assume the robot is at the same place at startup 
		✔ Use a "sliding window" to cull the possible image matches @20m @started(20-03-25 14:33) @done(20-03-25 14:44) @lasted(11m59s)
		✔ Downsample the matching resolution significantly (should lead to more robust performance) @started(20-03-25 10:53) @done(20-03-25 11:16) @lasted(23m22s)
		✔ Using full range of xcorr matching because currently the sides of the image are thrown away (most useful part) @started(20-03-25 15:03) @done(20-03-25 15:07) @lasted(4m49s)
		✔ Implement normxcorr2 @done(20-03-30 18:37)
		✔ Use basic scanline matching to determine rotation from images @1h @started(20-03-31 08:22) @done(20-03-31 09:18) @lasted(56m42s)
		☐ Implement a bio-inspired SLAM approach
			☐ Get range / bearing measurements from AR tags
			☐ Record data for offline processing (MATLAB)
			☐ Port to python to run in real-time
		✔ Larger along-route localisation window @done(20-05-13 10:20)
		✔ Filter out obvious bad offset localisations (threshold) @done(20-05-13 09:40)
			* Better approach to compare the ratio of correlations between top and second peak
		✔ Disable along-path localisation during a turn @done(20-06-29 13:29)
		✔ Threshold along-path localisation @done(20-05-20 16:26)
		✔ Apply small corrections continually @done(20-06-08 10:49)

	Control:
		✔ Make a basic controller to drive Miro straight @30m @started(20-03-26 10:01) @done(20-03-26 10:40) @lasted(39m28s)
		✔ Use a joystick to teleop Miro for smoother movement @done(20-04-02 12:37)

	ROS:
		✔ Make a nicer ordering for starting nodes (wait until camera is set and joints in position) @done(20-04-30 09:52)
		☐ Run everything onboard Miro
			☐ @low Port pose following to run onboard Miro at full 50 Hz
			☐ Connect controller to Miro via bluetooth (unsure if possible)
		✔ Publish the offset between odom and "map" frame @done(20-05-11 14:09)
		✔ Specify "intermediate" or "stop" goals - allow faster movement @15m @started(20-04-28 16:39) @done(20-04-28 16:59) @lasted(20m10s)
		✔ Refactor localiser and odom_follower into one node @30m @started(20-04-28 15:59) @done(20-04-28 16:30) @lasted(31m51s)
		☐ Allow the search range to be one-sided to allow localisation at the start and end
		☐ Write params to file on startup - each run
		☐ Sync image numbers between debug and full/norm?

	Visualisation:
		✔ Nice visualisation for image matching (include correlation vs offset plot) @20m @started(20-05-11 11:16) @done(20-05-11 12:22) @lasted(1h6m23s)
		✔ Record poses and offsets in data_matching @30m @started(20-05-11 13:30) @done(20-05-11 14:06) @lasted(36m55s)
		✔ Some way of visualising the corrections over a run @done(20-06-08 10:50)

Bugs: 
	ROS:
		✔ Subscribing to camera before setting camera options results in receiving empty message @20m @started(20-03-25 13:12) @done(20-03-25 13:28) @lasted(16m57s)

	Miro:
		✔ When commanding Miro to drive straight, it tends to turn right (right wheel locks). `/miro/sensors/wheel_speed_cmd` shows the right wheel speed sometimes set to 0. @done(20-04-28 10:47)
			Partly alleviated by using a controller to set the speeds based on integrated odometry - odometry drifts significantly though
			* Developer replied saying this was due to the cliff sensor stopping the wheel - testing whether disabling the sensors fixes this
				* seems to fix it (but hard to test without dark carpet)
		✔ The kinematic joints seem to do some caching, so ingore repeated commands (even as the joints move passively) @30m @started(20-03-25 15:22) @done(20-03-25 15:45) @lasted(23m39s)
		✔ Due to network latency, offboard odom integration is dropping messages, so integration errors occur @1h @started(20-04-06 08:32) @done(20-04-06 09:23) @lasted(51m47s)
		✔ The timestamp (of at least odom messages) occasionally overflows - causing big odom integration errors @done(20-05-11 14:10)
			* Developer replied - is a known issue and should have been fixed already...
			* Mitigated this problem for odometry integrating assuming a fixed 0.02 s timestep
		✔ Controlling the yaw of the head is unreliable, but it has a big effect on the driving @30m @started(20-04-29 16:39) @done(20-04-29 17:09) @lasted(30m49s)
		✔ Sometimes the localiser doesn't receive images - updates multiple times on old images @done(20-04-22 09:40)
			* This was an issue with the queue size of the ApproximateTimeSynchroniser
				set it large enough to account for delays in left/right image message delivery
		✔ Fixing the above created the opposite issue - that all images were synced, but a time delay accumulated @done(20-04-23 10:28)
			* Narrowed down to network issues -> chance of delay in receiving images, would typically build up over time
				described here: https://answers.ros.org/question/220502/image-subscriber-lag-despite-queue-1/
				Need to set the buffer size of the subscriber
			* Moved image synchronisation to onboard which appears to solve the problem
				Setting queue size to 1 and buff size large (maybe doesn't have an effect...) - still lag spikes but quickly recovered by dropping messages
		✔ We can't follow a spin-on-the-spot maneuvre because we only consider Euclidean distance for matching current position -> goal @done(20-05-13 11:18)
		✔ Sometimes in data_matching the system doesn't start driving - is the goal published before we're looking for it? @done(20-05-07 16:39)

	Localisation / Image Processing:
		✔ Why do the offsets come out all significantly negative? @15m @started(20-03-26 09:05) @done(20-03-26 09:11) @lasted(6m30s)
